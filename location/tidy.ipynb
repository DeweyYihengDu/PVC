{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divid the data form the `txt` to the single `csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "\n",
    "input_file = \"input.txt\"\n",
    "\n",
    "# Create output folder if not exists\n",
    "output_folder = \"output_csv_files\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with open(input_file, \"r\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "max_number = 6000  # Set the maximum number to process\n",
    "pattern = re.compile(r'^(\\d+):', re.MULTILINE)\n",
    "blocks = pattern.split(content)\n",
    "\n",
    "def process_line(line):\n",
    "    line_data = []\n",
    "    if ';' in line:\n",
    "        sublines = line.split(';')\n",
    "        for subline in sublines:\n",
    "            line_data.extend(process_line(subline))\n",
    "    else:\n",
    "        if line.startswith('Keywords:'):\n",
    "            line_data.append(('Keywords', line.split(':', 1)[1].strip()))\n",
    "        elif '/' in line and '=' in line:\n",
    "            key_value_pairs = re.findall(r'\\/([^=]+)=([^\\/]+)', line)\n",
    "            for key, value in key_value_pairs:\n",
    "                line_data.append((key.strip(), value.strip() if value.strip() else 'na'))\n",
    "        elif ':' in line and not ('/' in line and '=' in line):\n",
    "            key, value = line.rsplit(\":\", 1)\n",
    "            line_data.append((key.strip(), value.strip() if value.strip() else 'na'))\n",
    "    return line_data\n",
    "\n",
    "file_counter = 1\n",
    "for i in range(1, len(blocks), 2):\n",
    "    if file_counter > max_number:\n",
    "        break\n",
    "\n",
    "    block = blocks[i+1]\n",
    "    lines = block.strip().split(\"\\n\")\n",
    "    csv_data = []\n",
    "\n",
    "    for line in lines:\n",
    "        if \"Accession:\" in line and \"ID:\" in line:\n",
    "            accession, remaining = line.split(\"Accession:\", 1)[1].strip().split(\"ID:\", 1)\n",
    "            csv_data.append(('Accession', accession.strip()))\n",
    "            csv_data.append(('ID', remaining.strip()))\n",
    "        else:\n",
    "            csv_data.extend(process_line(line))\n",
    "\n",
    "    output_file = os.path.join(output_folder, f\"{blocks[i]}.csv\")\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        # Transpose the csv data and set the first row as column names\n",
    "        transposed_data = list(zip(*csv_data))\n",
    "        writer.writerow(transposed_data[0])\n",
    "        for row in transposed_data[1:]:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    file_counter += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the data from the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# 设置输入和输出文件名和路径\n",
    "input_folder = \"output_csv_files\"\n",
    "output_file = \"file.csv\"\n",
    "\n",
    "# 初始化合并后csv文件的列名和行数据列表\n",
    "merged_header = []\n",
    "merged_rows = []\n",
    "\n",
    "# 遍历所有csv文件并读取其内容\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        with open(os.path.join(input_folder, filename), \"r\") as file:\n",
    "            # 读取当前文件的第一行并将其添加到合并后的列名列表中\n",
    "            reader = csv.reader(file)\n",
    "            header = next(reader)\n",
    "            if not merged_header:\n",
    "                merged_header = header\n",
    "            else:\n",
    "                for column in header:\n",
    "                    if column not in merged_header:\n",
    "                        merged_header.append(column)\n",
    "\n",
    "            # 读取当前文件的所有行并将其添加到合并后的行数据列表中\n",
    "            for row in reader:\n",
    "                merged_row = {}\n",
    "                for i, value in enumerate(row):\n",
    "                    merged_row[header[i]] = value\n",
    "                merged_rows.append(merged_row)\n",
    "\n",
    "# 将合并后的列名和行数据写入输出文件\n",
    "with open(output_file, \"w\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=merged_header)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(merged_rows)\n",
    "# 删除空行\n",
    "with open(output_file, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "with open(output_file, 'w') as file:\n",
    "    lines = filter(lambda x: x.strip(), lines)\n",
    "    file.writelines(lines)\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
