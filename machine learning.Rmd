---
title: "machine learning"
output: 
  bookdown::html_document2:
    code_folding: show
    number_sections: no
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r,echo=FALSE,warning=FALSE,echo=FALSE}
library(randomForest)
library(glmnet)
library(Matrix)
library(tidyverse)
library(h2o)
library(corrr)
library(Hmisc)
library(ggpubr)
library(metafor)
library(forestploter)
```


# Predict the GC%

Load the data.

```{r}
pathway <- read.csv('./excel/results_with_env.csv')
data =pathway[,4:ncol(pathway)]
attach(data)
```




```{r}
cor_results <- rcorr(as.matrix(data))

# 将相关性结果和p值分别保存为data frame
cor_df <- as.data.frame(cor_results$r)
pvalue_df <- as.data.frame(cor_results$P)

# 获取"A"列的相关性和p值
cor_A <- cor_df["GC", ]
pvalue_A <- pvalue_df["GC", ]

# 创建一个新的data frame，包含变量名、相关性和p值
results <- data.frame(Variable = rownames(cor_A),
                      Correlation = as.numeric(cor_A),
                      Pvalue = as.numeric(pvalue_A))

# 筛选出p值小于0.05的列
selected_cols <- results %>% filter(Pvalue < 0.05)

# 绘制类似于森林图的结果
ggplot(selected_cols, aes(x = Variable, y = Correlation)) +
  geom_point() +
  geom_point(data = selected_cols %>% filter(Pvalue < 0.05), color = "red") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  labs(title = "Correlation with GC",
       subtitle = "Only correlations with p < 0.05 are shown",
       x = "Variable",
       y = "Correlation")
```

```{r}
selected_columns <- c()

# 获取数据表的列数
num_columns <- ncol(data)

# 循环遍历从第五列开始的其他列
for (i in 2:num_columns) {
  # 获取当前列的名称
  col <- colnames(data)[i]
  
  # 计算相关性并进行显著性检验
  result <- cor.test(data$GC, data[, col])
  
  # 检查p值是否小于0.05
  # 检查p值是否小于0.05，并且非零值数量大于一半
  if (result$p.value < 0.05 && sum(data[, col] != 0) > (nrow(data) / 2)) {
    selected_columns <- c(selected_columns, col)
  }
}
selected_columns
```

```{r}
selected_columns <- data.frame(Column = character(), P_Value = numeric(), Confidence_Interval = character())

# 获取数据表的列数
num_columns <- ncol(data)

# 循环遍历从第二列开始的其他列
for (i in 2:num_columns) {
  # 获取当前列的名称
  col <- colnames(data)[i]
  
  # 计算相关性并进行显著性检验
  result <- cor.test(data$GC, data[, col])
  
  # 检查p值是否小于0.05，并且非零值数量大于一半
  if (result$p.value < 0.05 && sum(data[, col] != 0) > (nrow(data) / 2)) {
    # 创建一个包含结果的行
    row <- data.frame(Column = col,
                      P_Value = result$p.value,
                      Confidence_Interval = paste(result$conf.int, collapse = " - "))
    
    # 将行添加到选定列的数据框中
    selected_columns <- rbind(selected_columns, row)
  }
}

selected_columns

```

```{r}
selected_columns$Confidence_Interval
```

```{r}
# 将区间拆分为两个数值
selected_columns$Confidence_Interval <- strsplit(selected_columns$Confidence_Interval, " - ")
selected_columns$Lower_Bound <- sapply(selected_columns$Confidence_Interval, function(x) as.numeric(x[1]))
selected_columns$Upper_Bound <- sapply(selected_columns$Confidence_Interval, function(x) as.numeric(x[2]))

# 移除原始的Confidence_Interval列
selected_columns$Confidence_Interval <- NULL
# 生成森林图
ggplot(selected_columns, aes(x = Column, y = P_Value, ymin = Lower_Bound, ymax = Upper_Bound)) +
  geom_pointrange() +
  coord_flip() +  # 将图形翻转为水平方向
  theme_classic()  # 使用经典主题
```

```{r}
# 将置信区间分割成两列
selected_columns$Confidence_Interval <- as.character(selected_columns$Confidence_Interval)
new_confidence_interval <- strsplit(selected_columns$Confidence_Interval, " - ")
selected_columns$CI_lower <- sapply(new_confidence_interval, "[[", 1)
selected_columns$CI_upper <- sapply(new_confidence_interval, "[[", 2)

```




```{r}
t_data=merge(data[,1]/100,data[,selected_columns])
data_long <- gather(t_data, key = "Variable", value = "Value", -x)
ggplot(data_long, aes(x = x, y = Variable, fill = Variable)) +
  geom_point(position = position_dodge(width = 0.7), size = 3, shape = 21) +
  geom_hline(yintercept = "", linetype = "dashed", color = "red") +
  labs(x = "x", y = "Variable", fill = "Variable")+
  theme_classic()
```

```{r}
x=KT
model1 <- lm(GC~x)
plot(GC,x)
summary(model1)
```

# Auto-Machine learning

```{r}
# 初始化h2o环境
h2o.init()

# 转换为H2OFrame
h2o_data <- as.h2o(data)
# 分割数据
# 将数据划分为训练集和验证集
splits <- h2o.splitFrame(h2o_data, ratios = 0.8)
train <- splits[[1]]
test  <- splits[[2]]

# 指定预测目标和输入特征
y <- "GC"  # 预测目标
x <- setdiff(names(h2o_data), y)  # 输入特征，去除预测目标的列

# 使用H2O的AutoML函数来训练模型
aml <- h2o.automl(x = x, y = y,
                  training_frame = train,
                  leaderboard_frame = test,
                  max_models = 20,
                  seed = 1)

# 打印出AutoML的排行榜
lb <- aml@leaderboard
print(lb)

# 使用最佳模型进行预测
preds <- h2o.predict(aml@leader, newdata = test)

# 打印出预测结果s
print(preds)
```




